# ğŸ§ª EDA para ClasificaciÃ³n de Productos: Nuevo vs Usado

> **PropÃ³sito:** Este anÃ¡lisis busca desarrollar una estrategia clara y accionable para clasificar productos como **nuevos** o **usados**, usando reglas interpretables derivadas del anÃ¡lisis exploratorio de datos (EDA).

---

## ğŸ” 1. Contexto y DecisiÃ³n Inicial

Ante la problemÃ¡tica planteada, se proporcionÃ³ un contexto inicial junto con un script que dividÃ­a el dataset en `train-test`. Sin embargo, esta estrategia no se alineaba con el enfoque adoptado en este desarrollo.  

En lugar de entrenar un modelo predictivo desde el inicio, se priorizÃ³ **comprender a fondo el comportamiento de los datos**. El objetivo fue generar lÃ³gica de negocio clara, interpretable y directamente aplicable, sin depender de modelos complejos ni infraestructura adicional.

> *AquÃ­ el EDA no es un paso previo: es la soluciÃ³n misma.*

La lÃ³gica resultante debe ser interpretable, auditable, y ejecutable sin necesidad de modelos externos, frameworks complejos ni infraestructura especializada.

### â—Â¿Por quÃ© no se usÃ³ una separaciÃ³n `train-test` o un modelado complejo?

La respuesta corta: **el tiempo es limitado y la simplicidad manda**â€¦ siempre que sea suficiente para cumplir los objetivos.

Pero mÃ¡s allÃ¡ del pragmatismo, la elecciÃ³n tambiÃ©n se fundamenta en una decisiÃ³n tÃ©cnica madura: este proyecto busca **entender los datos y derivar reglas claras, interpretables y listas para producciÃ³n**, sin depender de infraestructura adicional ni pipelines de entrenamiento.

MÃ¡s adelante en este documento se explora en detalle por quÃ© esta fue la mejor decisiÃ³n para el contexto actual.

---

## ğŸ› ï¸ 2. Procesamiento y SelecciÃ³n de Variables

Antes de aplicar cualquier transformaciÃ³n, se estableciÃ³ un supuesto fundamental:  
ğŸ”¹ **El sistema debe ser capaz de categorizar un producto como nuevo o usado en el momento exacto en que es publicado**, sin acceso a informaciÃ³n futura o a datos que requieran procesamiento complejo o asincrÃ³nico.

Este enfoque excluye explÃ­citamente variables que solo estÃ¡n disponibles despuÃ©s de la publicaciÃ³n (como `sold_quantity` o `stop_time`) o que requieren esfuerzo computacional no justificable para un MVP basado en reglas.

Adicionalmente, se priorizaron atributos:
- Que sean fÃ¡cilmente accesibles desde el JSON de entrada original
- Que reflejen informaciÃ³n visible al usuario o al sistema al momento de la creaciÃ³n
- Que puedan ser interpretados sin ambigÃ¼edad por un sistema de reglas

Con estos principios en mente, se realizÃ³ un anÃ¡lisis detallado variable por variable. A continuaciÃ³n se presenta un resumen representativo:

> âš ï¸ Esta tabla no resume todas las variables procesadas, sino una selecciÃ³n representativa de los distintos casos encontrados. Para ver el tratamiento completo, consultar el archivo [`data_converter.py`](./data_converter.py).

| CategorÃ­a | AcciÃ³n Tomada | Ejemplo | JustificaciÃ³n |
|----------|----------------|---------|---------------|
| `warranty`, `video_id`, `official_store_id` | Convertidas a booleanas por presencia (`True/False`) | Si `warranty = "6 meses"` â†’ `True`; si `NaN` â†’ `False` | La sola existencia de estos atributos ya es informativa. Su valor especÃ­fico es altamente variable y difÃ­cil de estandarizar, mientras que su ausencia puede reflejar un producto genÃ©rico o no institucional. |
| `sub_status`, `tags` | Retenidas como categÃ³ricas para futura dummificaciÃ³n | Si `sub_status = "suspended"` â†’ `sub_status_suspended = 1` | Estas variables contienen mÃºltiples categorÃ­as con valor semÃ¡ntico claro (como "suspended", "expired", "deleted"). Convertirlas a variables dummy permite capturar ese significado sin perder interpretabilidad. |
| `local_pickup`, `free_shipping`, `has_dimensions`, `accepts_mercadopago` | Convertidas a booleanas | Si `free_shipping = True`, se conserva; si `False` o `NaN`, se transforma en `False` | Estas variables provienen del diccionario `shipping`, y representan caracterÃ­sticas logÃ­sticas y de pago visibles al momento de publicar. Al ser estables y fÃ¡cilmente interpretables, se prestan bien para la generaciÃ³n de reglas. |
| `seller_address`,`permalink`, `id` | Eliminadas por ser irrelevantes, identificadores o no estructuradas | `seller_address["state"]["name"]` â†’ eliminado | Estas variables no aportan valor predictivo directo. Algunas son identificadores Ãºnicos, otras son constantes o requieren procesamiento avanzado (como imÃ¡genes), lo cual va en contra del principio de simplicidad del enfoque. |
| `start_time`, `stop_time`, `created_time`, `sold_quantity`, `available_quantity` | Eliminadas por no estar disponibles | `sold_quantity = 45` â†’ eliminado | Estas variables no estarÃ¡n disponibles **al momento de la creaciÃ³n de una nueva publicaciÃ³n**, que como se menciona antes de esta tabla, es el contexto especÃ­fico de este anÃ¡lisis. Por tanto, su uso no es vÃ¡lido en este escenario. |

> ğŸ“ Las transformaciones fueron diseÃ±adas pensando en su aplicabilidad en producciÃ³n y facilidad de mantenimiento. Se evitaron decisiones basadas en correlaciÃ³n superficial, priorizando aquellas con un respaldo conceptual claro y un impacto explicable en la predicciÃ³n.

---

## ğŸ“Š 3. AnÃ¡lisis Exploratorio

Una vez que los datos fueron limpiados, transformados y filtrados, se procediÃ³ al anÃ¡lisis grÃ¡fico para identificar **patrones de comportamiento relevantes respecto a la condiciÃ³n del artÃ­culo** (nuevo vs usado).

El criterio principal utilizado fue la **diferencia relativa entre clases**, no la frecuencia absoluta.

Por ejemplo:

- Si el 90â€¯% de los productos con `free_shipping = True` son nuevos, mientras que solo el 40â€¯% de los que no ofrecen envÃ­o gratuito lo son, esta variable revela un patrÃ³n estructural claro.

> ğŸ§  **Enfoque analÃ­tico:** Se priorizaron variables que mostraran diferencias proporcionales significativas entre clases, sin importar cuÃ¡n frecuentes fueran en tÃ©rminos absolutos. Lo que buscamos son seÃ±ales estructurales, no efectos de volumen.

---

## ğŸ§¾ 4. EvaluaciÃ³n de Texto

Se evaluÃ³ el uso del campo `title` mediante tÃ©cnicas de procesamiento de lenguaje natural (NLP), incluyendo modelos de Ãºltima generaciÃ³n.

Particularmente, se probaron **transformers preentrenados** como `facebook/bart-large-mnli` para clasificaciÃ³n cero-shot (zero-shot classification). Sin embargo, esta aproximaciÃ³n fue descartada por varios motivos:

- â±ï¸ **Tiempos de inferencia elevados**, incompatibles con pipelines ligeros y orientados a producciÃ³n rÃ¡pida  
- ğŸ“‰ **Rendimiento limitado**: los resultados obtenidos con tÃ­tulos reales fueron poco consistentes, incluso tras aplicar limpieza bÃ¡sica  
- ğŸ§  **Complejidad tÃ©cnica elevada**, que no se justificaba frente al bajo retorno observado

> En un contexto donde se busca un MVP robusto, interpretable y fÃ¡cilmente desplegable, se decidiÃ³ priorizar el uso de variables estructuradas, con comportamiento mÃ¡s estable y trazabilidad directa.

---

## ğŸŒ² 5. Ãrbol de DecisiÃ³n como Herramienta de Reglas

Se utilizÃ³ un modelo de tipo Ã¡rbol como herramienta de **EDA asistido**, no como modelo predictivo final. En particular, se empleÃ³ `XGBoost` configurado para generar Ã¡rboles interpretables, manteniendo asÃ­ la **legibilidad estructural** y permitiendo extraer lÃ³gica clara.

> ğŸ” **Esto NO es un modelo productivo. Es una herramienta para descubrir reglas lÃ³gicas robustas y comprensibles, directamente traducibles a cÃ³digo de negocio.**

### âš™ï¸ Consideraciones TÃ©cnicas

- Se limitÃ³ la profundidad de los Ã¡rboles (`max_depth`) para evitar reglas complejas y garantizar su trazabilidad.  
- La estructura de Ã¡rbol facilita la lectura y anÃ¡lisis de decisiones jerÃ¡rquicas, haciendo mÃ¡s evidente cÃ³mo ciertas combinaciones de variables llevan a una predicciÃ³n.  
- No se buscÃ³ maximizar la mÃ©trica de `accuracy_score`, sino **identificar condiciones estructurales sÃ³lidas y con alta `precision_score`**, que puedan aplicarse en producciÃ³n sin ambigÃ¼edad.

### âœ… Ventajas del Enfoque

- ğŸ§  **Alta interpretabilidad**: cada ruta del Ã¡rbol representa una secuencia clara de decisiones.  
- ğŸ§ª **ValidaciÃ³n por expertos no tÃ©cnicos**: las reglas pueden ser evaluadas por equipos de negocio sin requerir conocimiento de modelos.  
- ğŸ” **ReutilizaciÃ³n directa**: las condiciones se pueden implementar como `if`, filtros SQL o reglas en flujos ETL.  
- ğŸš€ **IteraciÃ³n rÃ¡pida**: permite generar, visualizar y ajustar reglas sin ciclos pesados de entrenamiento.

> El resultado es un conjunto de reglas extraÃ­das con base en estructura, no en correlaciÃ³n superficial, lo que refuerza su valor como lÃ³gica productiva confiable.

---

## ğŸ“Œ 6. MÃ©tricas Finales del Ãrbol Generado

| MÃ©trica    | Valor   |
|------------|---------|
| Accuracy   | 0.8678  |
| Precision  | 0.9051  |

<img src="./docs/Matrix.png" alt="Matriz de ConfusiÃ³n" width="500"/>

> Se priorizÃ³ la **precisiÃ³n** como mÃ©trica principal debido a su capacidad para reducir los errores tipo 1 (clasificar como *nuevo* algo que en realidad es *usado*), los cuales representan un riesgo directo para la experiencia del cliente.

Aunque la mÃ©trica de `accuracy` fue sÃ³lida y consistente, no refleja adecuadamente la gravedad de ciertos errores en el contexto de negocio. En particular, **la precisiÃ³n permite controlar mejor los falsos positivos**, es decir, cuando se clasifica como *nuevo* un producto que en realidad es *usado*. Este tipo de error genera:

- Reclamos postventa  
- DaÃ±o reputacional  
- PÃ©rdida de confianza y recompra

> En cambio, el error tipo 2 (clasificar como *usado* algo que es *nuevo*) es mucho menos crÃ­tico: no afecta negativamente la experiencia del cliente.

Es por esto que, como segunda mÃ©trica clave, se eligiÃ³ la **precisiÃ³n**. En este caso de uso, **reducir al mÃ¡ximo los errores tipo 1 es una prioridad**, ya que sus implicaciones pueden afectar directamente la satisfacciÃ³n del cliente, crear imprevistos operativos y deteriorar la percepciÃ³n general del servicio.

---

### ğŸ“„ Ãrbol completo de reglas

El Ã¡rbol generado con XGBoost estÃ¡ disponible en [`docs/Tree_rules.pdf`](./docs/Tree_rules.pdf). Aunque tiene una estructura algo extensa, fue necesario mantener este nivel de detalle para capturar casos particulares sin sacrificar precisiÃ³n ni interpretabilidad.

En este archivo pueden observarse de forma visual todas las **reglas lÃ³gicas de decisiÃ³n** generadas, cada una con su condiciÃ³n, predicciÃ³n final (`new` o `used`) y posiciÃ³n en el flujo de evaluaciÃ³n. Esto permite:

- **Auditar** fÃ¡cilmente las decisiones tomadas  
- **Traducir** las reglas directamente a filtros en SQL o Pandas  
- **Entender** quÃ© variables tienen mayor impacto en la clasificaciÃ³n

> En resumen, el Ã¡rbol no es un modelo en producciÃ³n, sino una herramienta de apoyo que permite extraer reglas robustas, trazables y listas para implementarse en entornos productivos reales.

---

## ğŸ§ª 7. ValidaciÃ³n de Reglas por Estabilidad

Se diseÃ±Ã³ un procedimiento especÃ­fico para validar que las reglas derivadas no estuvieran sobreajustadas al conjunto total:

- ğŸ”€ El dataset fue barajado y dividido en **100 bloques aleatorios**  
- ğŸ” En cada bloque se aplicaron las reglas generadas a partir del Ã¡rbol  
- ğŸ“ Se calcularon mÃ©tricas como `accuracy` y `precision` en cada segmento  

### ğŸ“ˆ VisualizaciÃ³n de Resultados por Bloque

<img src="./docs/Validation.png" alt="DistribuciÃ³n de MÃ©tricas por Bloque" width="600"/>

> Los resultados estÃ¡n fuertemente agrupados. Esto **descarta overfitting** y valida que las reglas tienen alta capacidad de generalizaciÃ³n.

Esta validaciÃ³n confirma que la lÃ³gica generada es robusta y puede usarse con confianza sobre nuevos registros sin degradaciÃ³n significativa.

---

## âš–ï¸ 8. Riesgos y Consideraciones

### Riesgos Potenciales:

- Sobreajuste si las reglas se replican sin control en un entorno cambiante  
- Cambios en los atributos disponibles por parte del proveedor de datos  
- Excesiva dependencia de variables estructurales que podrÃ­an desaparecer  

### Mitigaciones:

- Validaciones periÃ³dicas con nuevas muestras  
- Alertas automatizadas para monitorear falsos positivos  
- Registro detallado de lÃ³gica, supuestos y versionado  

---

## ğŸ”® 9. Recomendaciones Futuras

- Incluir variables de comportamiento post-publicaciÃ³n como `visitas`, `ventas`, `tiempo en lÃ­nea`  
- Reintroducir NLP si el rendimiento del pipeline lo permite  
- Enriquecer el anÃ¡lisis con retroalimentaciÃ³n de usuarios  
- Considerar un enfoque hÃ­brido: reglas simples + modelo supervisado para casos ambiguos  

---

## âœ… ConclusiÃ³n EstratÃ©gica

Este trabajo demuestra que un enfoque basado en **reglas estructuradas**, **visualmente interpretables** y **cuidadosamente validadas** puede ofrecer soluciones efectivas a problemas reales, especialmente en contextos donde se requiere:

- Bajo tiempo de desarrollo  
- Alta trazabilidad del comportamiento  
- Despliegue rÃ¡pido y seguro en entornos productivos  

> En la ingenierÃ­a **la mejor soluciÃ³n no es la mÃ¡s compleja**, sino la que entrega valor con claridad, rapidez y sostenibilidad.

### ğŸ“¦ AplicaciÃ³n en contextos Ã¡giles

En metodologÃ­as Ã¡giles como **Scrum**, lo importante no es la sofisticaciÃ³n tÃ©cnica, sino entregar **valor funcional real**, de forma iterativa y constante. Este enfoque responde a ese principio: construir un **MVP funcional**, fÃ¡cilmente comprensible y **alineado con los tiempos de negocio**.

Se evitÃ³ caer en **over-engineering innecesario**, priorizando una soluciÃ³n:

- **Ligera**, sin dependencias excesivas  
- **Auditada**, con lÃ³gica explicable paso a paso  
- **Transparente**, incluso para perfiles no tÃ©cnicos  

### ğŸ¤ ComunicaciÃ³n fluida con negocio

AdemÃ¡s, una soluciÃ³n basada en reglas claras permite que **todo el equipo â€”tÃ©cnico y no tÃ©cnicoâ€” entienda el funcionamiento del sistema**. Esto acelera la toma de decisiones, mejora la validaciÃ³n de hipÃ³tesis y fortalece la colaboraciÃ³n interfuncional.

La lÃ³gica generada puede implementarse directamente como:

- Filtros SQL  
- Condicionales en dashboards  
- Validaciones en pipelines existentes  

Todo esto **sin necesidad de reentrenamientos, monitoreo de drift o infraestructura especializada de ML en producciÃ³n**.

> Apostar por la simplicidad, cuando es suficiente, no solo es eficiente, tambiÃ©n es inclusivo.

---

## ğŸ§­ 11. JustificaciÃ³n TÃ©cnica

### Â¿Por quÃ© no ML, Deep Learning o pipelines avanzados?

Aunque viables, estos enfoques traen consigo:

- Complejidad operativa  
- Costos de entrenamiento y mantenimiento  
- Dificultad para auditar errores o explicar decisiones  

### En cambioâ€¦

- Las reglas actuales son **portables**, **verificables** y **entendibles** por negocio y tecnologÃ­a.  
- Se pueden desplegar en pipelines ligeros o incluso en SQL puro.  

---

## ğŸ§± 12. Ampliaciones TÃ©cnicas Futuras

Este MVP fue deliberadamente simple para acelerar su paso a producciÃ³n, pero su arquitectura lÃ³gica es totalmente escalable. A continuaciÃ³n se describe cÃ³mo podrÃ­a evolucionar hacia un sistema robusto y empresarial, basado en un stack moderno de Machine Learning Engineering:

### ğŸ“¦ 12.1. Ingesta y Procesamiento de Datos

- **Kafka** como sistema de ingesta en streaming, capturando eventos en tiempo real de productos nuevos/modificados desde el core de la plataforma.
- **Airflow** para la orquestaciÃ³n de pipelines ETL, con control detallado de dependencias lÃ³gicas y temporales.
- **Snowflake** como Data Warehouse principal, altamente escalable, ideal para staging, query batch, auditorÃ­a de histÃ³ricos y consultas analÃ­ticas complejas.

### ğŸ§ª 12.2. Entrenamiento y GestiÃ³n de Modelos

- **Databricks** como entorno colaborativo para exploraciÃ³n, transformaciÃ³n de datos y entrenamiento distribuido.
- **MLflow** embebido en Databricks para:
  - Tracking automÃ¡tico de experimentos (features, parÃ¡metros, mÃ©tricas)
  - Versionamiento de modelos en un *Model Registry* centralizado
  - Almacenamiento de artefactos: modelos, Ã¡rboles, datasets, mÃ©tricas validadas

> Todo bajo un enfoque reproducible, auditable y alineado con estÃ¡ndares MLOps.

### âš™ï¸ 12.3. Pipeline de Aprendizaje AutomÃ¡tico

- Reentrenamientos automÃ¡ticos programados vÃ­a **Airflow** ante:
  - CaÃ­das de precisiÃ³n o recall
  - DetecciÃ³n de *data drift* o *concept drift*
  - Cambios en catÃ¡logos, categorÃ­as o reglas de negocio
- ValidaciÃ³n previa en entorno `staging` con pruebas unitarias y regresiÃ³n de mÃ©tricas
- RevisiÃ³n automÃ¡tica de fairness, estabilidad y comportamiento por grupo/clase

### ğŸš€ 12.4. Despliegue en ProducciÃ³n

- **Docker** para contenerizaciÃ³n de modelos y lÃ³gica de negocio asociada
- **Kubernetes (K8s)** para orquestaciÃ³n:
  - Escalado horizontal automÃ¡tico
  - Balanceo de carga
  - Alta disponibilidad multi-nodo
- **CI/CD** completo:
  - ValidaciÃ³n automÃ¡tica del cÃ³digo y mÃ©tricas
  - Despliegue progresivo (Canary Release) con rollback automÃ¡tico si se detectan fallos
  - AutomatizaciÃ³n vÃ­a **GitHub Actions** o **ArgoCD**

### ğŸ§  12.5. Servicio de Inferencia

- API expuesta mediante **FastAPI** (Python) para integraciÃ³n inmediata con otros microservicios.
- Alternativa con **Go** si se prioriza baja latencia en entornos de alta demanda.
- AutenticaciÃ³n por tokens JWT, control de acceso, logging estructurado y trazabilidad completa.

### ğŸ“Š 12.6. Observabilidad y Monitoreo

- **Prometheus** recolectando:
  - Latencias, tasa de errores, nÃºmero de inferencias, uso de CPU/RAM
  - MÃ©tricas personalizadas como tasa de falsos positivos por tipo de producto
- **Grafana** como dashboard de monitoreo tÃ©cnico y de negocio:
  - Tendencias de precisiÃ³n, recall y accuracy por semana
  - Alarmas ante comportamiento anÃ³malo o degradaciÃ³n del sistema

### ğŸ”„ 12.7. Reentrenamiento Inteligente

- Seguimiento de *drift* mediante PSI, KS-Test y mÃ©tricas custom en pipelines de **Airflow**
- Triggers inteligentes ante:
  - Estacionalidad
  - Cambios en comportamiento de usuarios
  - RetroalimentaciÃ³n directa del cliente final (reclamos, devoluciones)
- Control de versiones con **MLflow** y validaciÃ³n progresiva

> ğŸ§  Este stack no solo es robusto, sino altamente mantenible, trazable, automatizado y alineado con los principios modernos de ingenierÃ­a de machine learning. Aunque este MVP se enfocÃ³ en reglas simples, su diseÃ±o permite escalar a modelos sofisticados sin comprometer el control ni la eficiencia operativa.

---

## ğŸ 13. Cierre

Este enfoque demuestra cÃ³mo un anÃ¡lisis exploratorio bien orientado puede entregar una soluciÃ³n robusta, mantenible y productiva.

> ğŸ“˜ *La mejor soluciÃ³n no siempre es la mÃ¡s compleja, sino la mÃ¡s adecuada al contexto.*

> â€œLa perfecciÃ³n se alcanza, no cuando no hay nada mÃ¡s que aÃ±adir, sino cuando no hay nada mÃ¡s que quitar.â€  
> â€” *Antoine de Saint-ExupÃ©ry*