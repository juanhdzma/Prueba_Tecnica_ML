# üß™ EDA para Clasificaci√≥n de Productos: Nuevo vs Usado

> **Prop√≥sito:** Este an√°lisis busca desarrollar una estrategia clara y accionable para clasificar productos como **nuevos** o **usados**, usando reglas interpretables derivadas del an√°lisis exploratorio de datos (EDA).

---

## üîç 1. Contexto y Decisi√≥n Inicial

Ante la problem√°tica planteada, se proporcion√≥ un contexto inicial junto con un script que divid√≠a el dataset en `train-test`. Sin embargo, esta estrategia no se alineaba con el enfoque adoptado en este desarrollo.  

En lugar de entrenar un modelo predictivo desde el inicio, se prioriz√≥ **comprender a fondo el comportamiento de los datos**. El objetivo fue generar l√≥gica de negocio clara, interpretable y directamente aplicable, sin depender de modelos complejos ni infraestructura adicional.

> *Aqu√≠ el EDA no es un paso previo: es la soluci√≥n misma.*

La l√≥gica resultante debe ser interpretable, auditable, y ejecutable sin necesidad de modelos externos, frameworks complejos ni infraestructura especializada.

### ‚ùó¬øPor qu√© no se us√≥ una separaci√≥n `train-test` o un modelado complejo?

La respuesta corta: **el tiempo es limitado y la simplicidad manda**‚Ä¶ siempre que sea suficiente para cumplir los objetivos.

Pero m√°s all√° del pragmatismo, la elecci√≥n tambi√©n se fundamenta en una decisi√≥n t√©cnica madura: este proyecto busca **entender los datos y derivar reglas claras, interpretables y listas para producci√≥n**, sin depender de infraestructura adicional ni pipelines de entrenamiento.

M√°s adelante en este documento se explora en detalle por qu√© esta fue la mejor decisi√≥n para el contexto actual.

---

## üõ†Ô∏è 2. Procesamiento y Selecci√≥n de Variables

Antes de aplicar cualquier transformaci√≥n, se estableci√≥ un supuesto fundamental:  
üîπ **El sistema debe ser capaz de categorizar un producto como nuevo o usado en el momento exacto en que es publicado**, sin acceso a informaci√≥n futura o a datos que requieran procesamiento complejo o asincr√≥nico.

Este enfoque excluye expl√≠citamente variables que solo est√°n disponibles despu√©s de la publicaci√≥n (como `sold_quantity` o `stop_time`) o que requieren esfuerzo computacional no justificable para un MVP basado en reglas.

Adicionalmente, se priorizaron atributos:
- Que sean f√°cilmente accesibles desde el JSON de entrada original
- Que reflejen informaci√≥n visible al usuario o al sistema al momento de la creaci√≥n
- Que puedan ser interpretados sin ambig√ºedad por un sistema de reglas

Con estos principios en mente, se realiz√≥ un an√°lisis detallado variable por variable. A continuaci√≥n se presenta un resumen representativo:

> ‚ö†Ô∏è Esta tabla no resume todas las variables procesadas, sino una selecci√≥n representativa de los distintos casos encontrados. Para ver el tratamiento completo, consultar el archivo [`data_converter.py`](./data_converter.py).

| Categor√≠a | Acci√≥n Tomada | Ejemplo | Justificaci√≥n |
|----------|----------------|---------|---------------|
| `warranty`, `video_id`, `official_store_id` | Convertidas a booleanas por presencia (`True/False`) | Si `warranty = "6 meses"` ‚Üí `True`; si `NaN` ‚Üí `False` | La sola existencia de estos atributos ya es informativa. Su valor espec√≠fico es altamente variable y dif√≠cil de estandarizar, mientras que su ausencia puede reflejar un producto gen√©rico o no institucional. |
| `sub_status`, `tags` | Retenidas como categ√≥ricas para futura dummificaci√≥n | Si `sub_status = "suspended"` ‚Üí `sub_status_suspended = 1` | Estas variables contienen m√∫ltiples categor√≠as con valor sem√°ntico claro (como "suspended", "expired", "deleted"). Convertirlas a variables dummy permite capturar ese significado sin perder interpretabilidad. |
| `local_pickup`, `free_shipping`, `has_dimensions`, `accepts_mercadopago` | Convertidas a booleanas | Si `free_shipping = True`, se conserva; si `False` o `NaN`, se transforma en `False` | Estas variables provienen del diccionario `shipping`, y representan caracter√≠sticas log√≠sticas y de pago visibles al momento de publicar. Al ser estables y f√°cilmente interpretables, se prestan bien para la generaci√≥n de reglas. |
| `seller_address`,`permalink`, `id` | Eliminadas por ser irrelevantes, identificadores o no estructuradas | `seller_address["state"]["name"]` ‚Üí eliminado | Estas variables no aportan valor predictivo directo. Algunas son identificadores √∫nicos, otras son constantes o requieren procesamiento avanzado (como im√°genes), lo cual va en contra del principio de simplicidad del enfoque. |
| `start_time`, `stop_time`, `created_time`, `sold_quantity`, `available_quantity` | Eliminadas por no estar disponibles | `sold_quantity = 45` ‚Üí eliminado | Estas variables no estar√°n disponibles **al momento de la creaci√≥n de una nueva publicaci√≥n**, que como se menciona antes de esta tabla, es el contexto espec√≠fico de este an√°lisis. Por tanto, su uso no es v√°lido en este escenario. |

> üìù Las transformaciones fueron dise√±adas pensando en su aplicabilidad en producci√≥n y facilidad de mantenimiento. Se evitaron decisiones basadas en correlaci√≥n superficial, priorizando aquellas con un respaldo conceptual claro y un impacto explicable en la predicci√≥n.

---

## üìä 3. An√°lisis Exploratorio

Una vez que los datos fueron limpiados, transformados y filtrados, se procedi√≥ al an√°lisis gr√°fico para identificar **patrones de comportamiento relevantes respecto a la condici√≥n del art√≠culo** (nuevo vs usado).

El criterio principal utilizado fue la **diferencia relativa entre clases**, no la frecuencia absoluta.

Por ejemplo:

- Si el 90‚ÄØ% de los productos con `free_shipping = True` son nuevos, mientras que solo el 40‚ÄØ% de los que no ofrecen env√≠o gratuito lo son, esta variable revela un patr√≥n estructural claro.

> üß† **Enfoque anal√≠tico:** Se priorizaron variables que mostraran diferencias proporcionales significativas entre clases, sin importar cu√°n frecuentes fueran en t√©rminos absolutos. Lo que buscamos son se√±ales estructurales, no efectos de volumen.

---

## üßæ 4. Evaluaci√≥n de Texto

Se evalu√≥ el uso del campo `title` mediante t√©cnicas de procesamiento de lenguaje natural (NLP), incluyendo modelos de √∫ltima generaci√≥n.

Particularmente, se probaron **transformers preentrenados** como `facebook/bart-large-mnli` para clasificaci√≥n cero-shot (zero-shot classification). Sin embargo, esta aproximaci√≥n fue descartada por varios motivos:

- ‚è±Ô∏è **Tiempos de inferencia elevados**, incompatibles con pipelines ligeros y orientados a producci√≥n r√°pida  
- üìâ **Rendimiento limitado**: los resultados obtenidos con t√≠tulos reales fueron poco consistentes, incluso tras aplicar limpieza b√°sica  
- üß† **Complejidad t√©cnica elevada**, que no se justificaba frente al bajo retorno observado

> En un contexto donde se busca un MVP robusto, interpretable y f√°cilmente desplegable, se decidi√≥ priorizar el uso de variables estructuradas, con comportamiento m√°s estable y trazabilidad directa.

---

## üå≤ 5. √Årbol de Decisi√≥n como Herramienta de Reglas

Se utiliz√≥ un modelo de tipo √°rbol como herramienta de **EDA asistido**, no como modelo predictivo final. En particular, se emple√≥ `XGBoost` configurado para generar √°rboles interpretables, manteniendo as√≠ la **legibilidad estructural** y permitiendo extraer l√≥gica clara.

> üîç **Esto NO es un modelo productivo. Es una herramienta para descubrir reglas l√≥gicas robustas y comprensibles, directamente traducibles a c√≥digo de negocio.**

### ‚öôÔ∏è Consideraciones T√©cnicas

- Se limit√≥ la profundidad de los √°rboles (`max_depth`) para evitar reglas complejas y garantizar su trazabilidad.  
- La estructura de √°rbol facilita la lectura y an√°lisis de decisiones jer√°rquicas, haciendo m√°s evidente c√≥mo ciertas combinaciones de variables llevan a una predicci√≥n.  
- No se busc√≥ maximizar la m√©trica de `accuracy_score`, sino **identificar condiciones estructurales s√≥lidas y con alta `precision_score`**, que puedan aplicarse en producci√≥n sin ambig√ºedad.

### ‚úÖ Ventajas del Enfoque

- üß† **Alta interpretabilidad**: cada ruta del √°rbol representa una secuencia clara de decisiones.  
- üß™ **Validaci√≥n por expertos no t√©cnicos**: las reglas pueden ser evaluadas por equipos de negocio sin requerir conocimiento de modelos.  
- üîÅ **Reutilizaci√≥n directa**: las condiciones se pueden implementar como `if`, filtros SQL o reglas en flujos ETL.  
- üöÄ **Iteraci√≥n r√°pida**: permite generar, visualizar y ajustar reglas sin ciclos pesados de entrenamiento.

> El resultado es un conjunto de reglas extra√≠das con base en estructura, no en correlaci√≥n superficial, lo que refuerza su valor como l√≥gica productiva confiable.

---

## üìå 6. M√©tricas Finales del √Årbol Generado

| M√©trica    | Valor   |
|------------|---------|
| Accuracy   | 0.8678  |
| Precision  | 0.9051  |

<img src="./docs/Matrix.png" alt="Matriz de Confusi√≥n" width="500"/>

> Se prioriz√≥ la **precisi√≥n** como m√©trica principal debido a su capacidad para reducir los errores tipo 1 (clasificar como *nuevo* algo que en realidad es *usado*), los cuales representan un riesgo directo para la experiencia del cliente.

Aunque la m√©trica de `accuracy` fue s√≥lida y consistente, no refleja adecuadamente la gravedad de ciertos errores en el contexto de negocio. En particular, **la precisi√≥n permite controlar mejor los falsos positivos**, es decir, cuando se clasifica como *nuevo* un producto que en realidad es *usado*. Este tipo de error genera:

- Reclamos postventa  
- Da√±o reputacional  
- P√©rdida de confianza y recompra

> En cambio, el error tipo 2 (clasificar como *usado* algo que es *nuevo*) es mucho menos cr√≠tico: no afecta negativamente la experiencia del cliente.

Es por esto que, como segunda m√©trica clave, se eligi√≥ la **precisi√≥n**. En este caso de uso, **reducir al m√°ximo los errores tipo 1 es una prioridad**, ya que sus implicaciones pueden afectar directamente la satisfacci√≥n del cliente, crear imprevistos operativos y deteriorar la percepci√≥n general del servicio.

---

### üìÑ √Årbol completo de reglas

El √°rbol generado con XGBoost est√° disponible en [`docs/Tree_rules.pdf`](./docs/Tree_rules.pdf). Aunque tiene una estructura algo extensa, fue necesario mantener este nivel de detalle para capturar casos particulares sin sacrificar precisi√≥n ni interpretabilidad.

En este archivo pueden observarse de forma visual todas las **reglas l√≥gicas de decisi√≥n** generadas, cada una con su condici√≥n, predicci√≥n final (`new` o `used`) y posici√≥n en el flujo de evaluaci√≥n. Esto permite:

- **Auditar** f√°cilmente las decisiones tomadas  
- **Traducir** las reglas directamente a filtros en SQL o Pandas  
- **Entender** qu√© variables tienen mayor impacto en la clasificaci√≥n

> En resumen, el √°rbol no es un modelo en producci√≥n, sino una herramienta de apoyo que permite extraer reglas robustas, trazables y listas para implementarse en entornos productivos reales.

---

## üß™ 7. Validaci√≥n de Reglas por Estabilidad

Se dise√±√≥ un procedimiento espec√≠fico para validar que las reglas derivadas no estuvieran sobreajustadas al conjunto total:

- üîÄ El dataset fue barajado y dividido en **100 bloques aleatorios**  
- üîÅ En cada bloque se aplicaron las reglas generadas a partir del √°rbol  
- üìè Se calcularon m√©tricas como `accuracy` y `precision` en cada segmento  

### üìà Visualizaci√≥n de Resultados por Bloque

<img src="./docs/Validation.png" alt="Distribuci√≥n de M√©tricas por Bloque" width="600"/>

> Los resultados est√°n fuertemente agrupados. Esto **descarta overfitting** y valida que las reglas tienen alta capacidad de generalizaci√≥n.

Esta validaci√≥n confirma que la l√≥gica generada es robusta y puede usarse con confianza sobre nuevos registros sin degradaci√≥n significativa.

---

## ‚öñÔ∏è 8. Riesgos y Consideraciones

### Riesgos Potenciales:

- Sobreajuste si las reglas se replican sin control en un entorno cambiante  
- Cambios en los atributos disponibles por parte del proveedor de datos  
- Excesiva dependencia de variables estructurales que podr√≠an desaparecer  

### Mitigaciones:

- Validaciones peri√≥dicas con nuevas muestras  
- Alertas automatizadas para monitorear falsos positivos  
- Registro detallado de l√≥gica, supuestos y versionado  

---

## üîÆ 9. Recomendaciones Futuras

- Incluir variables de comportamiento post-publicaci√≥n como `visitas`, `ventas`, `tiempo en l√≠nea`  
- Reintroducir NLP si el rendimiento del pipeline lo permite  
- Enriquecer el an√°lisis con retroalimentaci√≥n de usuarios  
- Considerar un enfoque h√≠brido: reglas simples + modelo supervisado para casos ambiguos  

---

## ‚úÖ Conclusi√≥n Estrat√©gica

Este trabajo demuestra que un enfoque basado en **reglas estructuradas**, **visualmente interpretables** y **cuidadosamente validadas** puede ofrecer soluciones efectivas a problemas reales, especialmente en contextos donde se requiere:

- Bajo tiempo de desarrollo  
- Alta trazabilidad del comportamiento  
- Despliegue r√°pido y seguro en entornos productivos  

> En la ingenier√≠a **la mejor soluci√≥n no es la m√°s compleja**, sino la que entrega valor con claridad, rapidez y sostenibilidad.

### üì¶ Aplicaci√≥n en contextos √°giles

En metodolog√≠as √°giles como **Scrum**, lo importante no es la sofisticaci√≥n t√©cnica, sino entregar **valor funcional real**, de forma iterativa y constante. Este enfoque responde a ese principio: construir un **MVP funcional**, f√°cilmente comprensible y **alineado con los tiempos de negocio**.

Se evit√≥ caer en **over-engineering innecesario**, priorizando una soluci√≥n:

- **Ligera**, sin dependencias excesivas  
- **Auditada**, con l√≥gica explicable paso a paso  
- **Transparente**, incluso para perfiles no t√©cnicos  

### ü§ù Comunicaci√≥n fluida con negocio

Adem√°s, una soluci√≥n basada en reglas claras permite que **todo el equipo ‚Äît√©cnico y no t√©cnico‚Äî entienda el funcionamiento del sistema**. Esto acelera la toma de decisiones, mejora la validaci√≥n de hip√≥tesis y fortalece la colaboraci√≥n interfuncional.

La l√≥gica generada puede implementarse directamente como:

- Filtros SQL  
- Condicionales en dashboards  
- Validaciones en pipelines existentes  

Todo esto **sin necesidad de reentrenamientos, monitoreo de drift o infraestructura especializada de ML en producci√≥n**.

> Apostar por la simplicidad, cuando es suficiente, no solo es eficiente, tambi√©n es inclusivo.

---

## üß≠ 11. Justificaci√≥n T√©cnica

### ¬øPor qu√© no ML, Deep Learning o pipelines avanzados?

Aunque viables, estos enfoques traen consigo:

- Complejidad operativa  
- Costos de entrenamiento y mantenimiento  
- Dificultad para auditar errores o explicar decisiones  

### En cambio‚Ä¶

- Las reglas actuales son **portables**, **verificables** y **entendibles** por negocio y tecnolog√≠a.  
- Se pueden desplegar en pipelines ligeros o incluso en SQL puro.  

---

## üß± 12. Ampliaciones T√©cnicas Futuras

Este MVP fue deliberadamente simple para acelerar su paso a producci√≥n, pero su arquitectura l√≥gica es totalmente escalable. A continuaci√≥n se describe c√≥mo podr√≠a evolucionar hacia un sistema robusto y empresarial, basado en un stack moderno de Machine Learning Engineering:

### üì¶ 12.1. Ingesta y Procesamiento de Datos

- **Kafka** como sistema de ingesta en streaming, capturando eventos en tiempo real de productos nuevos/modificados desde el core de la plataforma.
- **Airflow** para la orquestaci√≥n de pipelines ETL, con control detallado de dependencias l√≥gicas y temporales.
- **Snowflake** como Data Warehouse principal, altamente escalable, ideal para staging, query batch, auditor√≠a de hist√≥ricos y consultas anal√≠ticas complejas.

### üß™ 12.2. Entrenamiento y Gesti√≥n de Modelos

- **Databricks** como entorno colaborativo para exploraci√≥n, transformaci√≥n de datos y entrenamiento distribuido.
- **MLflow** embebido en Databricks para:
  - Tracking autom√°tico de experimentos (features, par√°metros, m√©tricas)
  - Versionamiento de modelos en un *Model Registry* centralizado
  - Almacenamiento de artefactos: modelos, √°rboles, datasets, m√©tricas validadas

> Todo bajo un enfoque reproducible, auditable y alineado con est√°ndares MLOps.

### ‚öôÔ∏è 12.3. Pipeline de Aprendizaje Autom√°tico

- Reentrenamientos autom√°ticos programados v√≠a **Airflow** ante:
  - Ca√≠das de precisi√≥n o recall
  - Detecci√≥n de *data drift* o *concept drift*
  - Cambios en cat√°logos, categor√≠as o reglas de negocio
- Validaci√≥n previa en entorno `staging` con pruebas unitarias y regresi√≥n de m√©tricas
- Revisi√≥n autom√°tica de fairness, estabilidad y comportamiento por grupo/clase

### üöÄ 12.4. Despliegue en Producci√≥n

- **Docker** para contenerizaci√≥n de modelos y l√≥gica de negocio asociada
- **Kubernetes (K8s)** para orquestaci√≥n:
  - Escalado horizontal autom√°tico
  - Balanceo de carga
  - Alta disponibilidad multi-nodo
- **CI/CD** completo:
  - Validaci√≥n autom√°tica del c√≥digo y m√©tricas
  - Despliegue progresivo (Canary Release) con rollback autom√°tico si se detectan fallos
  - Automatizaci√≥n v√≠a **GitHub Actions** o **ArgoCD**

### üß† 12.5. Servicio de Inferencia

- API expuesta mediante **FastAPI** (Python) para integraci√≥n inmediata con otros microservicios.
- Alternativa con **Go** si se prioriza baja latencia en entornos de alta demanda.
- Autenticaci√≥n por tokens JWT, control de acceso, logging estructurado y trazabilidad completa.

### üìä 12.6. Observabilidad y Monitoreo

- **Prometheus** recolectando:
  - Latencias, tasa de errores, n√∫mero de inferencias, uso de CPU/RAM
  - M√©tricas personalizadas como tasa de falsos positivos por tipo de producto
- **Grafana** como dashboard de monitoreo t√©cnico y de negocio:
  - Tendencias de precisi√≥n, recall y accuracy por semana
  - Alarmas ante comportamiento an√≥malo o degradaci√≥n del sistema

### üîÑ 12.7. Reentrenamiento Inteligente

- Seguimiento de *drift* mediante PSI, KS-Test y m√©tricas custom en pipelines de **Airflow**
- Triggers inteligentes ante:
  - Estacionalidad
  - Cambios en comportamiento de usuarios
  - Retroalimentaci√≥n directa del cliente final (reclamos, devoluciones)
- Control de versiones con **MLflow** y validaci√≥n progresiva

> üß† Este stack no solo es robusto, sino altamente mantenible, trazable, automatizado y alineado con los principios modernos de ingenier√≠a de machine learning. Aunque este MVP se enfoc√≥ en reglas simples, su dise√±o permite escalar a modelos sofisticados sin comprometer el control ni la eficiencia operativa.

---

## üèÅ 13. Cierre

Este enfoque demuestra c√≥mo un an√°lisis exploratorio bien orientado puede entregar una soluci√≥n robusta, mantenible y productiva.

> üìò *La mejor soluci√≥n no siempre es la m√°s compleja, sino la m√°s adecuada al contexto.*

> ‚ÄúLa perfecci√≥n se alcanza, no cuando no hay nada m√°s que a√±adir, sino cuando no hay nada m√°s que quitar.‚Äù  
> ‚Äî *Antoine de Saint-Exup√©ry*